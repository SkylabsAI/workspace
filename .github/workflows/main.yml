name: Main

on:
  workflow_call:

permissions:
  pull-requests: write # for posting comments to pull requests
  packages: read # for accessing our docker registry

env:
  WORKDIR: "/tmp/build-dir"  # NOTE: Keep in sync with second occurrence at the bottom
  CI_FILES_ARTIFACT: "ci-files" # Artifact name, used by [gen-job] and all jobs that depend on it
  SCRATCHDIR: "/tmp/scratch"
  COMMITS_JOB: "commits_job.txt"
  COMMITS_BASE: "commits_base.txt"
  DUNE_TARGETS: "@fmdeps/all @fmdeps/runtest @psi/all @psi/runtest @bluerock/bhv/proof @bluerock/NOVA/all"
  BOILERPLATE: "/home/coq/activate.inc.sh"
  CLICOLOR: "1"
  GNUMAKEFLAGS: "--no-print-directory"
  OCAMLRUNPARAM: "a=2,o=120,s=256M"
  DUNE_CACHE_STORAGE_MODE: "copy"
  DUNE_CONFIG__BACKGROUND_DIGESTS: "disabled"
  DUNE_PROFILE: "br_timing"
  UV_LINK_MODE: "copy"
  ROCQ_LOG_PREFIX: bluerock
  OPAM_PACKAGES: opam pin | grep -E "/fmdeps/(auto|BRiCk|vendored/(vscoq|coq-lsp))" | grep -E -v "rocq-bluerock-cpp-(demo|stdlib)"

jobs:
  gen-job:
    runs-on:
      group: FM
    container:
      image: "ghcr.io/skylabsai/workspace:fm-default"
      options: "-v=/cache:/cache:ro -v=/home/coq/.ssh:/home/coq/.ssh -v=/home/coq/dune_nfs/dune_cache:/home/coq/.cache --security-opt seccomp=/home/coq/seccomp.json"
      env:
        NJOBS: "16"
        BASH_ENV: "/home/coq/.profile"
    outputs:
      compare: ${{ steps.config.outputs.compare }}
      pr_number: ${{ steps.config.outputs.pr_number }}
    steps:
      # When running from workspace we are forced to explicitly check out
      # workspace in order to run actions within workspace from the file system
      - name: "Checkout workspace (from workspace)"
        if: github.repository == 'SkylabsAI/workspace'
        uses: actions/checkout@v5
      - name: "Initialize workspace (from workspace)"
        if: github.repository == 'SkylabsAI/workspace'
        uses: ./.github/actions/initialize_workspace
        with:
          FM_CI_TOKEN: ${{ secrets.FM_CI_TOKEN }}
      - name: "Initialize workspace (from elsewhere)"
        if: github.repository != 'SkylabsAI/workspace'
        uses: SkylabsAI/workspace/.github/actions/initialize_workspace@main
        with:
          FM_CI_TOKEN: ${{ secrets.FM_CI_TOKEN }}
      - id: config
        uses: ./workspace_checkout/.github/actions/config
        with:
          FM_CI_TOKEN: ${{ secrets.FM_CI_TOKEN }}
      - id: artifact
        name: "Upload actions and workflows"
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.CI_FILES_ARTIFACT }}
          path: |
            workspace_checkout/.github/actions/*
            workspace_checkout/.github/workflows/*


  workspace-success:
    needs: [opam-build, full-build, python-build]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: "Check successes"
        shell: bash
        run: |
          echo "Checking that opam-build succeeded"
          ${{ needs.opam-build.result == 'success' && 'true' || 'false' }}
          echo "Checking that full-build succeeded"
          ${{ needs.full-build.result == 'success' && 'true' || 'false' }}
          echo "Checking that python-build succeeded"
          ${{ needs.python-build.result == 'success' && 'true' || 'false' }}


  opam-build:
    needs: gen-job
    defaults:
      run:
        shell: bash
        working-directory: ${{ env.WORKDIR }}
    runs-on:
      group: FM
    container:
      image: "ghcr.io/skylabsai/workspace:fm-default"
      options: "-v /cache:/cache:ro -v /home/coq/.ssh:/home/coq/.ssh -v /home/coq/dune_nfs/dune_cache:/home/coq/.cache --security-opt seccomp=/home/coq/seccomp.json"
    steps:
      - name: "Download CI files"
        uses: actions/download-artifact@v5
        with:
          name: ${{ env.CI_FILES_ARTIFACT }}
      - name: "Prepare Workspace"
        uses: ./actions/prepare_workspace
        with:
          FM_CI_TOKEN: ${{ secrets.FM_CI_TOKEN }}
      - name: "Checkout Job Commits"
        uses: ./actions/checkout_workspace
      - id: build-job
        name: "Opam Install"
        run: |
          source ${{ env.BOILERPLATE }}
          ./fmdeps/fm-ci/docker/opam_build.sh "${{ env.ROCQ_LOG_PREFIX }}" '${{ env.OPAM_PACKAGES }}'

  python-gen-job:
    needs: [gen-job]
    if: |
      !cancelled() &&
      needs.gen-job.result == 'success'
    outputs:
      matrix: ${{ steps.matrix.outputs.matrix-combinations }}
    name: "Python: Generate Jobs"
    defaults:
      run:
        shell: bash
        working-directory: ${{ env.WORKDIR }}
    runs-on:
      group: FM
    container:
      image: "ghcr.io/skylabsai/workspace:fm-default"
      options: "-v /cache:/cache:ro -v /home/coq/.ssh:/home/coq/.ssh -v /home/coq/dune_nfs/dune_cache:/home/coq/.cache --security-opt seccomp=/home/coq/seccomp.json"
      env:
        NJOBS: "16"
        BASH_ENV: "/home/coq/.profile"
    steps:
      - name: "Download CI files"
        uses: actions/download-artifact@v5
        with:
          name: ${{ env.CI_FILES_ARTIFACT }}
      - name: "Prepare Workspace"
        uses: ./actions/prepare_workspace
        with:
          FM_CI_TOKEN: ${{ secrets.FM_CI_TOKEN }}
      - name: "Checkout Job Commits"
        uses: ./actions/checkout_workspace

      - name: "Nuke bluerock repos"
        run: |
          make bluerock-nuke CONFIRM=yes
      - name: "Build matrix include list"
        id: "matrix"
        run: |
          source ${{ env.BOILERPLATE }}
          touch matrix
          for PROJECT in $(find -name 'pyproject.toml' | grep -vE '\bpsi\b'); do
            PROJECT_DIR=$(dirname $PROJECT)
            PROJECT=$(uvx --directory $PROJECT_DIR --from toml-cli toml get --toml-path pyproject.toml project.name)
            echo $PROJECT: $PROJECT_DIR
            # TASKS=$(uvx --directory $PROJECT_DIR --from taskipy task --list | grep -Eo '^[^ ]+_ci\b')
            (uvx --directory $PROJECT_DIR --from taskipy task --list \
               | grep -Eo '^[^ ]+_ci\b' > tasks) \
              || (echo -n "" > tasks)
            cat tasks
            for TASK in $(cat tasks); do
              { grep -Eq '_ocaml_ci$' && OCAML="true" || OCAML="false"; }
              echo '{"project":"'${PROJECT}'",
                     "project-dir":"'${PROJECT_DIR}'",
                     "ocaml":'${OCAML}',
                     "task":"'${TASK}'"},' \
                | tee -a matrix
            done
          done
          echo matrix-combinations={\"include\":[$(cat matrix)]} | tee -a "$GITHUB_OUTPUT"

  python-build:
    needs: [python-gen-job]
    # We depend on [full-build] only to populate the cache; we do not care if it
    # failed.
    if: |
      !cancelled() &&
      needs.python-gen-job.result == 'success'
    continue-on-error: true
    defaults:
      run:
        shell: bash
        working-directory: ${{ env.WORKDIR }}
    runs-on:
      group: FM
    container:
      image: "ghcr.io/skylabsai/workspace:fm-default"
      options: "-v /cache:/cache:ro -v /home/coq/.ssh:/home/coq/.ssh -v /home/coq/dune_nfs/dune_cache:/home/coq/.cache --security-opt seccomp=/home/coq/seccomp.json"
      env:
        NJOBS: "16"
        BASH_ENV: "/home/coq/.profile"
    strategy:
      matrix: ${{ fromJson(needs.python-gen-job.outputs.matrix) }}
    name: "Python: ${{ matrix.project }}: ${{ matrix.task }}${{ matrix.ocaml && '(with OCaml)' || '' }}"
    steps:
      - name: "Download CI files"
        uses: actions/download-artifact@v5
        with:
          name: ${{ env.CI_FILES_ARTIFACT }}
      - name: "Prepare Workspace"
        uses: ./actions/prepare_workspace
        with:
          FM_CI_TOKEN: ${{ secrets.FM_CI_TOKEN }}
      - name: "Checkout Job Commits"
        uses: ./actions/checkout_workspace

      - name: "Build OCaml dependencies"
        if: |
          !cancelled() &&
          matrix.ocaml
        run: |
          source ${{ env.BOILERPLATE }}
          echo "::group::make -s stage1"
          make -j${NJOBS} -s stage1
          echo "::endgroup::"
          echo "::group::dune build .."
          dune b @fmdeps/install @psi/install
          echo "::endgroup::"

      - name: "${{ matrix.project }}: ${{ matrix.task }}"
        run: |
          export PATH=$(pwd)/_build/install/default/bin:$PATH
          uv --directory ${{ matrix.project-dir }} run task ${{ matrix.task }}


  full-build:
    needs: gen-job
    defaults:
      run:
        shell: bash
        working-directory: ${{ env.WORKDIR }}
    runs-on:
      group: FM
    container:
      image: "ghcr.io/skylabsai/workspace:fm-default"
      options: "-v=/cache:/cache:ro -v=/home/coq/.ssh:/home/coq/.ssh -v=/home/coq/dune_nfs/dune_cache:/home/coq/.cache --security-opt seccomp=/home/coq/seccomp.json"
      env:
        NJOBS: "16"
        BASH_ENV: "/home/coq/.profile"
    steps:
      - name: "Download CI files"
        uses: actions/download-artifact@v5
        with:
          name: ${{ env.CI_FILES_ARTIFACT }}
      - name: "Prepare Workspace"
        uses: ./actions/prepare_workspace
        with:
          FM_CI_TOKEN: ${{ secrets.FM_CI_TOKEN }}

      - name: "Checkout Job Commits"
        uses: ./actions/checkout_workspace

      - name: "Create Directory structure for dune"
        run: |
          mkdir -p ~/.cache/ ~/.config/dune/
          cp fmdeps/fm-ci/ci/dune_config ~/.config/dune/config
      - name: "Test stack limit"
        run: |
          source ${{ env.BOILERPLATE }}
          ulimit -S -s

      - id: build-job-asts
        name: "Build Job ASTs"
        run: |
          source ${{ env.BOILERPLATE }}
          make -s -j${NJOBS} stage1

      ### NOTE: Every job after here should be resilient to build-job-asts
      ### and/or build-job steps failing. Use [if: '!cancelled()'] with quotes
      ### or a multi-line version.

      - id: build-job
        if: |
          !cancelled()
        name: "Build Job Proofs"
        run: |
          source ${{ env.BOILERPLATE }}
          # Actual build.
          dune build _build/install/default/bin/filter-dune-output
          dune build -j${NJOBS} ${{ env.DUNE_TARGETS }} 2>&1 | _build/install/default/bin/filter-dune-output
      - name: "Extract Job Data"
        if: |
          !cancelled() &&
          needs.gen-job.outputs.compare == '1'
        run: |
          source ${{ env.BOILERPLATE }}
          # Print information on the size of the _build directory.
          du -hs _build
          du -hc $(find _build -type f -name "*.v") | tail -n 1
          du -hc $(find _build -type f -name "*.vo") | tail -n 1
          du -hc $(find _build -type f -name "*.glob") | tail -n 1
          # Extract data.
          find _build/ -name '*.vo'| sort | xargs md5sum > ${{ env.SCRATCHDIR }}/md5sums.txt
          dune exec -- globfs.extract-all ${NJOBS} _build/default
          # echo -e "\e[0Ksection_start:`date +%s`:section_9[collapsed=true]\r\e[0KGenerate code quality report"
          (cd _build/default; dune exec -- coqc-perf.report .) | tee -a coq_codeq.log
          cat coq_codeq.log | dune exec -- coqc-perf.code-quality-report > ${{ env.SCRATCHDIR }}/gl-code-quality-report.json || true
          # echo -e "\e[0Ksection_end:`date +%s`:section_9\r\e[0K"
          dune exec -- coqc-perf.extract-all _build/default perf-data
          dune exec -- hint-data.extract-all ${NJOBS} perf-data
          du -hs _build
          du -hs perf-data
          mv perf-data ${{ env.SCRATCHDIR }}/perf-data
          rsync -a --prune-empty-dirs --include="*/" --include="*.d" --exclude="*" _build/ ${{ env.SCRATCHDIR }}/build_vd

      - name: "Checkout Base Commits"
        uses: ./actions/checkout_workspace
        if: |
          !cancelled() &&
          needs.gen-job.outputs.compare == '1'
        with:
          CHECKOUT_BASE: true

      - name: "Build Base ASTs"
        if: |
          !cancelled() &&
          needs.gen-job.outputs.compare == '1'
        run: |
          source ${{ env.BOILERPLATE }}
          make -s -j${NJOBS} stage1
      - name: "Build Base Proofs"
        if: |
          !cancelled() &&
          needs.gen-job.outputs.compare == '1'
        run: |
          source ${{ env.BOILERPLATE }}
          # Actual build.
          dune build _build/install/default/bin/filter-dune-output
          (dune build -j${NJOBS} ${{ env.DUNE_TARGETS }}  2>&1 | _build/install/default/bin/filter-dune-output)
      - name: "Extract Base Data"
        if: |
          !cancelled() &&
          needs.gen-job.outputs.compare == '1'
        run: |
          source ${{ env.BOILERPLATE }}
          # Print information on the size of the _build directory.
          du -hs _build
          du -hc $(find _build -type f -name "*.v") | tail -n 1
          du -hc $(find _build -type f -name "*.vo") | tail -n 1
          du -hc $(find _build -type f -name "*.glob") | tail -n 1
          # Extract data.
          find _build/ -name '*.vo'| sort | xargs md5sum > ${{ env.SCRATCHDIR }}/md5sums_ref.txt
          dune exec -- globfs.extract-all ${NJOBS} _build/default
          dune exec -- coqc-perf.extract-all _build/default perf-data
          dune exec -- hint-data.extract-all ${NJOBS} perf-data
          du -hs _build
          du -hs perf-data
          mv perf-data ${{ env.SCRATCHDIR }}/perf-data_ref

      #### PERF ANALYSIS ####
      - name: "Checkout Job Commits (again)"
        uses: ./actions/checkout_workspace
        if: |
          !cancelled() &&
          needs.gen-job.outputs.compare == '1'


      - name: "Performance Analysis"
        if: |
          !cancelled() &&
          needs.gen-job.outputs.compare == '1'
        run: |
          source ${{ env.BOILERPLATE }}
          dune build fmdeps/BRiCk/rocq-tools
          mv ${{ env.SCRATCHDIR }}/perf-data perf-data
          mv ${{ env.SCRATCHDIR }}/perf-data_ref perf-data_ref
          cp perf-data/perf_summary.csv ${{ env.SCRATCHDIR }}/perf_summary.csv
          cp perf-data_ref/perf_summary.csv ${{ env.SCRATCHDIR }}/perf_summary_ref.csv
          dune exec -- coqc-perf.summary-diff --no-colors --instr-threshold 1 perf-data_ref/perf_summary.csv perf-data/perf_summary.csv > ${{ env.SCRATCHDIR }}/perf_analysis.md
          dune exec -- coqc-perf.summary-diff --no-colors --instr-threshold 1 --csv perf-data_ref/perf_summary.csv perf-data/perf_summary.csv > ${{ env.SCRATCHDIR }}/perf_analysis.csv
          dune exec -- coqc-perf.summary-diff --no-colors --instr-threshold 1 --gitlab --diff-base-url "https://skylabs_ai.gitlab.io/-/FM/fm-ci/-/jobs/${CI_JOB_ID}/artifacts/perf-report" perf-data_ref/perf_summary.csv perf-data/perf_summary.csv > ${{ env.SCRATCHDIR }}/perf_analysis_gitlab.md

          echo "Performance summary for ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" > ${{ env.SCRATCHDIR }}/perf_analysis_comment.md
          echo "" >> ${{ env.SCRATCHDIR }}/perf_analysis_comment.md
          dune exec -- coqc-perf.summary-diff --no-colors --instr-threshold 1 --github perf-data_ref/perf_summary.csv perf-data/perf_summary.csv | tee | tee -a ${{ env.SCRATCHDIR }}/perf_analysis_comment.md >> $GITHUB_STEP_SUMMARY

          dune exec -- coqc-perf.html-diff-all perf-data_ref perf-data ${{ env.SCRATCHDIR }}/perf-report
          # Adding hint data diff
          find perf-data_ref -type f -name "*.hints.csv" | dune exec -- coqc-perf.gather-hint-data > ${{ env.SCRATCHDIR }}/hint-data_ref.csv
          find perf-data -type f -name "*.hints.csv" | dune exec -- coqc-perf.gather-hint-data > ${{ env.SCRATCHDIR }}/hint-data.csv
          dune exec -- coqc-perf.hint-data-diff ${{ env.SCRATCHDIR }}/hint-data_ref.csv ${{ env.SCRATCHDIR }}/hint-data.csv > hint_data_diff.md
          dune exec -- coqc-perf.hint-data-diff --html ${{ env.SCRATCHDIR }}/hint-data_ref.csv ${{ env.SCRATCHDIR }}/hint-data.csv > ${{ env.SCRATCHDIR }}/hint_data_diff.html
          head -n 202 hint_data_diff.md > hint_data_diff_truncated.md
          echo -e "\n<details><summary>[Hint data diff](https://skylabs_ai.gitlab.io/-/FM/fm-ci/-/jobs/${CI_JOB_ID}/artifacts/hint_data_diff.html)</summary>\n" >> ${{ env.SCRATCHDIR }}/perf_analysis_gitlab.md
          cat hint_data_diff_truncated.md >> ${{ env.SCRATCHDIR }}/perf_analysis_gitlab.md
          if ! cmp -s hint_data_diff.md hint_data_diff_truncated.md; then
            echo "| ... | ... | ... | ... |" >> ${{ env.SCRATCHDIR }}/perf_analysis.gitlab.md
          fi
          echo -e '\n</details>\n' >> ${{ env.SCRATCHDIR }}/perf_analysis_gitlab.md
          # python3 support/fm-perf/post_fm_perf.py --access-token ${PROOF_PERF_TOKEN} --project-id 74911021 --mr-id 3913 -f ${{ env.SCRATCHDIR }}/perf_analysis_gitlab.md --pipe-url "https://gitlab.com/skylabs_ai/FM/auto/-/pipelines/2116778517"

      - name: "Post Performance Analysis Comment"
        if: |
          !cancelled() &&
          needs.gen-job.outputs.compare == '1' &&
          needs.gen-job.outputs.pr_number != ''
        run: |
          # create json-encoded file
          uv run python3 -c 'import json, sys; print(json.dumps({"body": sys.stdin.read()}))' \
            < ${{ env.SCRATCHDIR }}/perf_analysis_comment.md \
            > ${{ env.SCRATCHDIR }}/perf_analysis_comment.json
          curl -L \
            --fail-with-body \
            -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/${{ github.repository }}/issues/${{ needs.gen-job.outputs.pr_number }}/comments \
            -d @${{ env.SCRATCHDIR }}/perf_analysis_comment.json


      - name: "Upload Artifacts"
        if: |
          !cancelled() &&
          github.event_name != 'push'
        uses: actions/upload-artifact@v4
        with:
          name: "reports"
          if-no-files-found: ignore
          path: |
            ${{ env.SCRATCHDIR }}/commits.txt
            ${{ env.SCRATCHDIR }}/ast_md5sums.txt
            ${{ env.SCRATCHDIR }}/md5sums.txt
            ${{ env.SCRATCHDIR }}/fm-stats
            ${{ env.SCRATCHDIR }}/hint-data.csv
            ${{ env.SCRATCHDIR }}/perf_summary.csv
            ${{ env.SCRATCHDIR }}/commits_ref.txt
            ${{ env.SCRATCHDIR }}/ast_md5sums_ref.txt
            ${{ env.SCRATCHDIR }}/md5sums_ref.txt
            ${{ env.SCRATCHDIR }}/perf-report
            ${{ env.SCRATCHDIR }}/perf_analysis.md
            ${{ env.SCRATCHDIR }}/perf_analysis.csv
            ${{ env.SCRATCHDIR }}/perf_analysis_gitlab.md
            ${{ env.SCRATCHDIR }}/hint_data_diff.html
            ${{ env.SCRATCHDIR }}/hint-data_ref.csv
            ${{ env.SCRATCHDIR }}/perf_summary_ref.csv
